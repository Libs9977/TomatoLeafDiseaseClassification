"C:\Users\libas\Desktop\COURS 2020\FINAL UNIVERSITY\IDEES DE PROJETS\catsAndDogs\Scripts\python.exe" "C:\Users\libas\Desktop\COURS 2020\FINAL UNIVERSITY\COURSES\THESIS\Program\catsAndDogs\AlexNetModel.py" 
2025-07-21 15:04:30.237125: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-21 15:04:31.042013: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Found 18197 images belonging to 10 classes.
Found 3760 images belonging to 10 classes.
Found 360 images belonging to 10 classes.
C:\Users\libas\Desktop\COURS 2020\FINAL UNIVERSITY\IDEES DE PROJETS\catsAndDogs\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-07-21 15:04:35.113287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "sequential"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 55, 55, 96)     │        34,944 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 27, 27, 96)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 27, 27, 256)    │       614,656 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 13, 13, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 13, 13, 384)    │       885,120 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (None, 13, 13, 384)    │     1,327,488 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_4 (Conv2D)               │ (None, 13, 13, 256)    │       884,992 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_2 (MaxPooling2D)  │ (None, 6, 6, 256)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (None, 9216)           │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 4096)           │    37,752,832 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 4096)           │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 4096)           │    16,781,312 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 4096)           │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 10)             │        40,970 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 58,322,314 (222.48 MB)
 Trainable params: 58,322,314 (222.48 MB)
 Non-trainable params: 0 (0.00 B)
C:\Users\libas\Desktop\COURS 2020\FINAL UNIVERSITY\IDEES DE PROJETS\catsAndDogs\Lib\site-packages\keras\src\optimizers\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.
  warnings.warn(
Epoch 1/30
C:\Users\libas\Desktop\COURS 2020\FINAL UNIVERSITY\IDEES DE PROJETS\catsAndDogs\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
569/569 - 1841s - 3s/step - accuracy: 0.3284 - loss: 1.8987
Epoch 2/30
569/569 - 1589s - 3s/step - accuracy: 0.4952 - loss: 1.4339
Epoch 3/30
569/569 - 1661s - 3s/step - accuracy: 0.5945 - loss: 1.1436
Epoch 4/30
2025-07-20 14:10:01.069972: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 1 of 8
2025-07-20 14:10:01.542720: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.
569/569 - 1763s - 3s/step - accuracy: 0.6796 - loss: 0.9112
Epoch 5/30
569/569 - 1502s - 3s/step - accuracy: 0.7405 - loss: 0.7498
Epoch 6/30
569/569 - 1509s - 3s/step - accuracy: 0.7910 - loss: 0.6162
Epoch 7/30
569/569 - 1613s - 3s/step - accuracy: 0.8220 - loss: 0.5140
Epoch 8/30
569/569 - 1967s - 3s/step - accuracy: 0.8517 - loss: 0.4431
Epoch 9/30
569/569 - 1752s - 3s/step - accuracy: 0.8707 - loss: 0.3832
Epoch 10/30
569/569 - 1510s - 3s/step - accuracy: 0.8908 - loss: 0.3377
Epoch 11/30
569/569 - 1515s - 3s/step - accuracy: 0.9003 - loss: 0.2998
Epoch 12/30
569/569 - 1525s - 3s/step - accuracy: 0.9184 - loss: 0.2487
Epoch 13/30
569/569 - 1882s - 3s/step - accuracy: 0.9235 - loss: 0.2268
Epoch 14/30
569/569 - 2288s - 4s/step - accuracy: 0.9306 - loss: 0.2143
Epoch 15/30
569/569 - 1787s - 3s/step - accuracy: 0.9399 - loss: 0.1837
Epoch 16/30
569/569 - 1523s - 3s/step - accuracy: 0.9460 - loss: 0.1647
Epoch 17/30
569/569 - 1517s - 3s/step - accuracy: 0.9465 - loss: 0.1629
Epoch 18/30
569/569 - 1519s - 3s/step - accuracy: 0.9552 - loss: 0.1317
Epoch 19/30
569/569 - 1765s - 3s/step - accuracy: 0.9552 - loss: 0.1383
Epoch 20/30
569/569 - 1568s - 3s/step - accuracy: 0.9611 - loss: 0.1150
Epoch 21/30
569/569 - 1527s - 3s/step - accuracy: 0.9674 - loss: 0.0982
Epoch 22/30
569/569 - 1828s - 3s/step - accuracy: 0.9703 - loss: 0.0869
Epoch 23/30
569/569 - 1531s - 3s/step - accuracy: 0.9688 - loss: 0.0997
Epoch 24/30
569/569 - 1527s - 3s/step - accuracy: 0.9704 - loss: 0.0865
Epoch 25/30
569/569 - 1603s - 3s/step - accuracy: 0.9730 - loss: 0.0846
Epoch 26/30
569/569 - 2013s - 4s/step - accuracy: 0.9744 - loss: 0.0813
Epoch 27/30
569/569 - 1615s - 3s/step - accuracy: 0.9776 - loss: 0.0720
Epoch 28/30
569/569 - 1529s - 3s/step - accuracy: 0.9798 - loss: 0.0635
Epoch 29/30
569/569 - 1554s - 3s/step - accuracy: 0.9768 - loss: 0.0708
Epoch 30/30
569/569 - 1585s - 3s/step - accuracy: 0.9816 - loss: 0.0609
12/12 ━━━━━━━━━━━━━━━━━━━━ 15s 1s/step - accuracy: 0.9094 - loss: 0.5388
Test loss: 0.5729532837867737
Test accuracy: 0.894444465637207
Confusion matrix, without normalization
[[39  0  0  0  0  0  1  0  0]
 [ 0 34  0  0  0  0  4  2  0]
 [ 0  0 40  0  0  0  0  0  0]
 [ 0  3  0 29  0  0  8  0  0]
 [ 0  0  0  0 33  0  7  0  0]
 [ 0  0  0  0  0 40  0  0  0]
 [ 0  0  1  0  0  0 39  0  0]
 [ 1  0  2  0  0  0  7 30  0]
 [ 0  0  0  0  0  1  1  0 38]]
